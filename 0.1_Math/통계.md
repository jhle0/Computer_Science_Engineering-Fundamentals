# 기술통계(Descriptive)와 추론통계(Inferential) 정리

---

## 모집단, 표본, 편향

### 모집단 (Population)

- 관심 대상 전체 집단
- 크기: N
- 모집단 평균: μ
- 모집단 분산: σ²

### 표본 (Sample)

- 모집단에서 뽑은 일부 데이터
- 크기: n
- 표본 평균: x̄
- 표본 분산: s²

### 편향 (Bias)

표본이 모집단을 “대표”하지 못하면 추론이 깨진다.

- **선택 편향(Selection bias)**: 특정 성향의 사람/데이터가 더 뽑힘 (예: 특정 시간대에만 설문)
- **자기선택 편향(Self-selection bias)**: 참여를 “자발적으로” 선택한 사람만 들어옴 (예: 온라인 투표)
- **생존자 편향(Survivorship bias)**: 살아남은/남아있는 데이터만 봄 (예: 망한 기업 제외하고 성공 요인 분석)
- **비응답 편향(Non-response bias)**: 응답하지 않은 집단이 체계적으로 다름

---

## 기술 통계

데이터 자체를 요약/설명한다. (추론·일반화는 하지 않음)

### 1. 중심 경향 (Central Tendency)

### 평균 (Mean)

- **표본 평균**

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space \bar{x}=\frac{1}{n}\sum_{i=1}^{n}x_i$

- **모집단 평균**

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  \mu=\frac{1}{N}\sum_{i=1}^{N}x_i$

### 중앙값 (Median)

- 정렬했을 때 가운데 값(또는 가운데 두 값의 평균)
- 이상치(outlier)에 평균보다 덜 민감

### 최빈값 (Mode)

- 가장 자주 관측되는 값
- bimodal: 최빈값이 2개인 분포

---

### 2. 산포 (Dispersion)

### 분산 (Variance)

- **모집단 분산**

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  \sigma^2=\frac{1}{N}\sum_{i=1}^{N}(x_i-\mu)^2$

- **표본 분산**

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  s^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2$

- 표본에서 분모가 n이 아니라 n−1인 이유: 평균 x̄를 표본으로부터 추정해서 자유도 1이 줄어들기 때문(불편성 확보)

### 표준편차 (Standard Deviation)

- 분산의 제곱근 → 원 단위로 환산해 더 의미 있는 값으로 사용 가능

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  \sigma=\sqrt{\sigma^2},\quad s=\sqrt{s^2}$

---

### 3. 정규분포 (Normal / Gaussian)

- 평균 근처 밀도가 가장 크고 좌우 대칭인 종 모양 분포
- μ가 중심, σ가 퍼짐(스케일)을 결정

### 확률밀도함수 (PDF)

연속형에서 “확률”이 아니라 “밀도”를 주는 함수다. 실제 확률은 면적(적분)으로 계산한다

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  f(x)=\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$

### 누적분포함수 (CDF)

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  F(x)=P(X\le x)=\int_{-\infty}^{x} f(t)\,dt$

### 역 CDF (Quantile function)

확률 p에 해당하는 값 x를 반환한다

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  F^{-1}(p)=x\ \text{such that}\ F(x)=p$

가설검정/신뢰구간에서 임계값(critical value) 구할 때 사용한다

---

### 4. Z-score (표준화)

서로 단위/평균/분산이 다른 값을 같은 척도에서 비교한다

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  z=\frac{x-\mu}{\sigma}$

**예시(집값 비교)**

- A동네: $μ_A$=140000, $σ_A$=3000, $x_A$=150000

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  z_A=\frac{150000-140000}{3000}=\frac{10000}{3000}\approx 3.33$

- B동네: $μ_B$=800000, $σ_B$=10000, $x_B$=815000

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  z_B=\frac{815000-800000}{10000}=\frac{15000}{10000}=1.5$

평균 대비 상대적으로 더 비싼 집은 A동네 집이다. (z-score가 더 큼)

---

## 2. 추론 통계 (Inferential Statistics)

표본으로부터 모집단에 대한 결론(추정/검정)을 내리는것

핵심은 표본오차와 불확실성(분포)을 정량화하는 것이다

### 중심극한정리 (CLT)

모집단이 정규가 아니더라도 n이 충분히 크면 표본평균의 분포가 정규에 가까워진다.

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  \bar{X}\approx \mathcal{N}\left(\mu,\frac{\sigma^2}{n}\right)$

- 보통의 충분한 n의 크기는 31이상
- “n≥31”은 규칙(rule of thumb)일 뿐이며, 데이터 왜도/꼬리 두께에 따라 더 큰 n이 필요할 수도 있다.

### 신뢰구간 (Confidence Interval, CI)

표본 평균이 → 모집단 평균의 특정 범위에 속한다고 얼마나 확실하게 믿는지

**(1) σ를 알고 있을 때 (또는 n이 매우 커서 근사)**

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  \bar{x}\ \pm\ z_{\alpha/2}\cdot \frac{\sigma}{\sqrt{n}}$

**(2) σ를 모를 때(현실 대부분) → t-분포**

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  \bar{x}\ \pm\ t_{\alpha/2,\ n-1}\cdot \frac{s}{\sqrt{n}}$

- 용어 정리
    - 유의수준: α = 1 − 신뢰수준 (95% CI면 α=0.05)
    - 임계값: z_{α/2} 또는 t_{α/2,n−1}
    - 허용오차(Margin of Error)

$\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space  ME = (\text{critical value})\times SE(\bar{x})$

## p-value

귀무가설 H0가 참이라고 가정했을 때, 관측한 결과(검정통계량)와 같거나 더 극단적인 결과가 나올 확률이다.

→우연히 어떤 일이 일어날 확률

**예시)**

누군가가 라면을 먹어보고

이 라면이 스프를 먼저 넣었는지 아니면 면을 먼저 넣었는지 맞추는 능력이 있다고 해보자

8번의 실험을 했을 때

이 사람의 능력이 아니라 우연히 이런일이 일어날 확률은 70분의1 인 1.4%이다

여기서 관심 대상의 변수가 실험에 영향을 미치지 않았으며 긍정적인 결과는 우연한 운에 불과하다는 → 귀무 가설($H_0$)을 세울수 있고

문제의 변수(통제 변수)가 긍정적인 결과를 야기했다는 대립가설($H_1$)을 세울 수 있다

> 일반적으로
> 
> 
> 통계적 유의성의 임계값은 5%로
> 
> 이보다 낮으면 귀무가설을 기각하고 대립가설을 지지할 수 있다
> 

### t-분포 (Student’s t)

- σ를 모르고 s로 대체할 때, 특히 n이 작으면 불확실성이 커진다 → t-분포
- 특징: 정규분포보다 꼬리가 두꺼움(극단값 가능성을 더 크게 반영)

누군가가 라면을 먹어보고

이 라면이 스프를 먼저 넣었는지 아니면 면을 먼저 넣었는지 맞추는 능력이 있다고 해보자

8번의 실험을 했을 때

이 사람의 능력이 아니라 우연히 이런일이 일어날 확률은 70분의1 인 1.4%이다
