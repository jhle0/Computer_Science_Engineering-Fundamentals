# 3.1-2 Processes and Threads

> Active recall
> 
> - A **process** is not just “a program in execution,” but an **execution unit** that bundles multiple things together. Describe its main components at a high level.
> - How are **PCB / context / context switching** related to each other?
>     
>     (Explain what each one does, and why they should be understood together.)
>     
> - Explain the **memory layout of a process (code / data / BSS / heap / stack)** from a high-level perspective, and classify which regions are **static** and which are **dynamic**.
> - Why are process states (`new, ready, running, blocked, terminated, suspended`) divided into these multiple stages?
>     
>     From the OS’s point of view, **what is it trying to manage** with this state model?
>     
> - Why are the **process hierarchy (parent/child)** and the `fork()`–`exec()` pattern important from a system-wide perspective?
>     
>     (Answer in terms of how the OS organizes processes and starts new programs.)
>     
> - What role does a **thread** play inside a process?
>     
>     Compare **process vs thread** at a high level from the perspective of **resource sharing vs separation**.
>     
> - When comparing **multi-process vs multi-thread**, why can we describe it as a trade-off between
>     
>     **isolation & stability** vs **resource efficiency & performance**?
>     

---

## Process Overview

### What Is a Process?

- In general, a process is called a **“program in execution.”**
- More precisely, it is an **execution unit** that includes
    
    **the program code + the resources allocated to execute that code**
    
    (memory, open files, CPU state, etc.).
    
- **Foreground process**
    - A process that runs in a context the user can directly see (terminal, GUI window, etc.).
    - Examples: an editor launched from a terminal, GUI applications, web browsers, etc.
- **Background process**
    - A process that the user does not see directly but **runs in the background and provides functionality.**
    - Among these, those that do not interact directly with the user and provide system services are:
        - On Unix-like systems: **daemons**
        - On Windows: **services**

### Process Control Block (PCB)

- A **PCB (Process Control Block)** is a kernel data structure that stores **various pieces of information about a process**.
- When a process is created, a PCB is created in the **kernel space**,
    
    and when the process terminates, its PCB is removed as well.
    

**Typical information stored in a PCB**

- **Process ID (PID)**: a unique identifier for the process
- **Register values**: the complete CPU register state at the time the process was running
- **Process state**: `new / ready / running / blocked / terminated / suspended`, etc.
- **CPU scheduling information**: priority, position in scheduling queues, etc.
- **Memory management information**: page table base address, base/limit registers, etc.
- **Open file and I/O information**: file descriptors, assigned I/O devices
- Others: parent/child process info, signal handling info, and more

> In other words, PCB = “the complete set of information needed to resume this process.”
> 

### Process Context

A **context** is the **entire state that must be remembered** in order to later resume execution of a process.

Typically, it includes:

- **Hardware context (CPU execution state)**
    - Program Counter (PC)
    - General-purpose registers
    - Status/flag registers, etc.
- **Process address space (logical address space)**
    - Code, data, BSS, heap, stack
- **Kernel data structures related to the process**
    - PCB
    - **Kernel stack**: the stack used during system calls and interrupt handling

### Context Switching

- A **context switch** is the process by which the CPU **switches execution from process A to process B**.

High-level flow:

1. A timer interrupt, I/O completion interrupt, system call, or exception occurs,
    
    giving the OS an opportunity to take control.
    
2. The OS saves the **context of the currently running process A** (registers, PC, etc.) into its PCB.
3. It then loads the context stored in the PCB of process B and **restores it into the CPU.**
4. The CPU resumes execution from process B.

> Context switching is the mechanism that lets multiple processes take turns using the CPU in very short time slices.
> 
> 
> As a result, from the user’s perspective, it **looks as if many processes are running at the same time.**
> 

---

## Memory Layout of a Process

When a process is created:

- In **kernel space**, the OS allocates structures such as the PCB and a kernel stack for that process.
- In **user space**, the OS allocates the process’s address space.

A typical (logical) layout from top to bottom is:

1. **Code segment (Text segment)**
2. **Data segment** (initialized global/static variables)
3. **BSS segment** (uninitialized global/static variables)
4. **Heap**
5. **Stack**

### Code Segment (Text)

- The segment that stores **executable machine code**.
- Usually **read-only**, and in some systems the same code segment can be shared among multiple processes (e.g., multiple instances of the same program).

### Data Segment

- Stores **data whose values persist throughout program execution**.
- Typically contains **initialized global variables and static variables**.

### BSS Segment

- Stores **global and static variables that are declared without an explicit initializer**.
- The executable does not store the actual values for these variables; instead, it contains
    
    **information such as “reserve this much space for zero-initialized global/static variables.”**
    
- When the program is loaded, the OS/runtime **initializes this segment to zero.**
- The reason for separating the data segment and BSS segment is:
    - Only data with explicit initial values needs to be stored on disk,
        
        which **reduces executable size and makes loading more efficient.**
        

### Heap

- Stores **dynamically allocated memory** during program execution.
    - For example, memory obtained via `malloc`, `new`, etc.
- The programmer is responsible for allocation and deallocation.
    - If allocated memory is not freed, a **memory leak** occurs.

### Stack

- Stores **temporary data used for function calls**:
    - Function parameters, local variables, return addresses, etc.
- Grows and shrinks automatically as functions are called and return.

> Because the sizes of the code and data segments are fixed at program start, they are called statically allocated regions.
> 
> 
> The heap and stack can grow and shrink during execution, so they are called **dynamically allocated regions**.
> 
> Conceptually, we often say that **the heap grows upward (toward higher addresses)** and
> 
> **the stack grows downward (toward lower addresses)** so that they grow toward each other.
> 

---

## Process States and Hierarchy

### Process States

As it runs, a process transitions through several states.

**Typical states**

- **new**: the process has just been created and is being loaded into memory
- **ready**: the process is prepared to run but is **waiting for CPU time**
- **running**: the process is currently executing on the CPU
- **blocked (waiting)**: the process cannot use the CPU because it is **waiting for some event**, such as I/O completion
- **terminated**: the process has finished execution and has **ended**
- **suspended (stopped)**:
    - The process is **temporarily paused** for an external reason (user-issued `stop`, OS policy, swapped out, etc.).
    - In some models, this is further divided into `suspended ready`, `suspended blocked`, etc.

### Process Hierarchy

- While running, a process can use a **system call to create a new process.**
- In this case:
    - The process that initiates creation is the **parent process**.
    - The newly created process is the **child process**.
- In this way, processes form a **tree structure**, called the **process hierarchy**.
    - On Unix-like systems, a special **root process** such as `init` or `systemd` sits at the top.

### Process Creation: `fork` and `exec` (Unix Model)

- **`fork()`**
    - Creates a new child process by **duplicating the current process**.
    - Parent and child share the same code and address space structure, but
        
        **have different PIDs and logically separate memory**
        
        (in practice, copy-on-write optimizations may be used).
        
- **`exec()`**
    - A system call that **replaces the current process’s code, data, stack, and heap** with a new program.
    - The PID remains the same, but **the program being executed changes.**

Typical pattern:

1. The parent process calls `fork()` to create **a copy of itself (the child)**.
2. The child process calls `exec()` to replace its memory space with a **different program** and start running it.

---

## Threads

### What Is a Thread?

- A **thread** is a **unit of execution (a single flow of control)** inside a process.
- Traditionally, there was only **one execution flow per process** (single-threaded).
    
    With the introduction of threads, **a single process can have multiple execution flows running concurrently.**
    

> In Linux, both processes and threads are regarded as “contexts of execution,”
> 
> 
> and internally they are unified under a single data structure called a **task** (e.g., `task_struct`).
> 

### Process vs Thread

**Resources owned per process**

- Its own **address space** (code, data, heap)
- An open file table
    
    (usually shared by threads within the same process, but separate across different processes)
    
- Various kernel data structures (PCB, etc.)

**Resources shared by threads within the same process**

- Code segment, data segment, heap
- Open files, sockets, and most other resources

**Resources private to each thread**

- Thread ID
- **Program Counter and register state**
- **Stack**

> In short, a thread has only the minimal execution state (PC, registers, stack) as private data,
> 
> 
> and **shares most other resources** with other threads in the same process.
> 

### Multi-process vs Multi-thread

- **Multi-process**
    - Running multiple **independent processes** at the same time.
    - Each process uses its own **separate address space**.
- **Multi-thread**
    - Running **multiple threads within a single process** at the same time.
    - Threads share the **same address space (code/data/heap)**.

**Pros and cons**

- **Multi-process**
    - Pros:
        - Strong **isolation and robustness**, thanks to separated memory spaces.
        - If one process crashes, it tends to have less impact on others.
    - Cons:
        - Context switches between processes are more expensive.
        - Data sharing is harder and requires IPC (pipes, sockets, shared memory, etc.).
        - Running many processes that do similar work can increase memory usage due to **duplicated code/data**.
- **Multi-thread**
    - Pros:
        - Since threads within a process share code/data/heap,
            
            they can **use memory more efficiently.**
            
        - Context switches between threads are typically **lighter** than between processes.
        - Even if one thread is blocked on I/O, other threads in the same process can still use the CPU.
    - Cons:
        - Because memory is shared, it is easy to introduce **race conditions, deadlocks**, and other concurrency bugs.
        - A single faulty thread can corrupt the entire process’s memory, causing **the whole process to crash.**
