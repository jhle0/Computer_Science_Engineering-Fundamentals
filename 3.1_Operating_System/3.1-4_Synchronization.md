# 3.1-4 Synchronization

> Active recall
> 
> - What are the two main purposes of **synchronization**?
>     
>     (Explain them in terms of **execution ordering** and **mutual exclusion**.)
>     
> - Describe the relationship between **shared resource / critical section / race condition**.
>     
>     (Define each one and explain, step by step, how a race condition arises.)
>     
> - Using the **Producer–Consumer** problem as an example,
>     
>     explain why **mutual exclusion** is necessary, and why we also need **execution ordering (condition synchronization)**.
>     
> - Compare a **mutex lock** and a **semaphore**.
>     - Common point: what are both used for?
>     - Differences: how many resources they can represent (1 vs N), usage pattern, and how they relate to busy waiting vs block/wakeup.
> - Conceptually, what do the semaphore operations `wait(P)` and `signal(V)` do?
>     
>     (Answer from both perspectives: resource count and blocking/waking processes.)
>     
> - In what ways is a **monitor** a safer and more convenient abstraction for programmers than a semaphore?
>     
>     (Explain in terms of grouping shared data with its interface, automatic mutual exclusion, and condition variables.)
>     
> - In a monitor, what is the role of a **condition variable**,
>     
>     and in what situations are `wait()` and `signal()` called? Explain using the Producer–Consumer example.
>     

---

## What is Synchronization?

When multiple processes (or threads) run **concurrently**,

they often **exchange data and share resources** such as files, variables, and devices.

If they are allowed to run “all at once with no rules,” then:

- Shared data can become **corrupted**, and
- The execution order can get messed up so that we **cannot guarantee correct results**.

To prevent this, the operating system provides **synchronization mechanisms**:

> Synchronization = controlling when different execution flows (processes/threads) run
> 
> 
> and **how** they access shared resources.
> 

---

### Process / Thread Synchronization

Synchronization has two main goals:

1. **Execution ordering (order synchronization)**
    - Ensuring certain operations happen in a **specific order**,
        
        e.g., “B must run only **after** A has finished.”
        
2. **Mutual exclusion**
    - Ensuring that only **one** execution flow at a time can access a resource
        
        that must not be used concurrently (shared variables, files, etc.).
        

> Not only processes, but also threads are targets of synchronization.
> 
> 
> In other words, **any execution flow (process or thread)** can require synchronization.
> 

---

### Example: Execution Ordering

Execution ordering means making concurrently running processes execute in the **correct order**.

Example:

- A `Writer` process: writes some value to `data.txt`
- A `Reader` process: reads the value from `data.txt`

In this case:

- The `Reader` must **not** run before the `Writer` has written the value.
- If the Reader runs first without ordering:
    - It might read an **empty file** or an **old value**.

So the OS / programmer must ensure:

- The Reader only runs **after** the Writer has finished writing.
    
    → This is **synchronization for execution ordering**.
    

---

### Mutual Exclusion

**Mutual exclusion** means:

> Ensuring that only one process/thread at a time
> 
> 
> can access a shared resource that must not be used concurrently.
> 

A classic example: the **Producer–Consumer problem**

- Shared resource: a **buffer**.
    - Producer: **inserts** data into the buffer.
    - Consumer: **removes** data from the buffer.
- Suppose we have a variable like `count` representing the current number of items.

Problem:

- Producer does: `count++`
- Consumer does: `count--`
- If these two operations execute at the same time, depending on the timing of reads/writes,
    
    `count` can end up with a value that does **not match the actual buffer state**
    
    → this is a **race condition**.
    

Solution:

- Group the operations on `count` and the buffer into a **critical section**
    
    and ensure that **only one execution flow** can enter that section at a time
    
    (using a mutex, semaphore, monitor, etc.).
    

---

### Shared Resource, Critical Section, Race Condition

- **Shared resource**
    
    A resource that multiple processes/threads **use in common**.
    
    Examples: global variables, files, devices (printers, disks), sockets, etc.
    
- **Critical section**
    
    A section of code that **accesses a shared resource**,
    
    where **two or more execution flows must not run that code at the same time**.
    

**Problem: Race condition**

- A **race condition** occurs when two or more execution flows
    
    run a critical section **concurrently**, and
    
    the **final result depends on the timing or interleaving** of their operations.
    
- When a race condition happens,
    
    **data consistency** is broken and the outcome becomes unpredictable.
    

Therefore:

> Synchronization for mutual exclusion =
> 
> 
> controlling multiple processes/threads so that
> 
> they **cannot be in the critical section at the same time**.
> 

---

## Synchronization Techniques

Now, **how do we actually implement** synchronization?

Goals:

- Ensure that **only one** execution flow can be in a **critical section** at a time (mutual exclusion)
- When necessary, guarantee the **correct execution order** (condition synchronization)

Main techniques:

- Mutex lock
- Semaphore
- Monitor

---

### Mutex Lock

A mutex lock is the most basic **mutual exclusion primitive**.

Analogy: a **fitting room in a clothing store**

- One fitting room, one lock:
    - If the door is locked → **someone is using it**
    - If the door is unlocked → **you can enter and lock it**

**Concept**

- **Global variable `lock`**: a flag indicating the state of the lock (0: unlocked, 1: locked)
- **`acquire()`**: called **before entering** the critical section
- **`release()`**: called **after finishing** the critical section

Conceptual implementation:

```c
acquire() {
    while (lock == 1) {
        // Someone is using it → wait (busy wait)
    }
    lock = 1;  // I lock it
}

release() {
    lock = 0;  // Done using it, unlock
}

```

- `acquire()` is called **before entering the critical section**:
    - If it is already locked → **keep checking** until it becomes free
    - If it is free → set `lock = 1` and enter
- `release()` is called **when leaving** the critical section:
    - Sets `lock = 0` so that other execution flows can enter.

> Continuously checking the lock while it is held is called
> 
> 
> **busy waiting (spinning)**.
> 
> → You are consuming CPU cycles while waiting.
> 

In real OS implementations:

- For **very short** critical sections, this may be used as a **spinlock**.
- More generally, the kernel will:
    - **Block** the waiting thread (put it to sleep) when it cannot acquire the lock, and
    - **Wake it up** when the lock becomes available, to reduce overhead.

---

### Semaphore

A semaphore is a **more general synchronization primitive** than a mutex.

- Mutex:
    - Specialized for the case “**only 1 at a time**”.
- Semaphore:
    - Can express conditions like “**up to N can enter at the same time**”.

**Basic concept**

- Global variable `S`: an integer representing the **number of available resources**
- `wait(S)` / `P(S)` / `down(S)`:
    - Request: “I want to **use one unit** of this resource.”
- `signal(S)` / `V(S)` / `up(S)`:
    - Notification: “I’m **done** using one unit of this resource.”

Conceptual busy-wait version:

```c
wait(S) {
    while (S <= 0) {
        // No available resource → wait (busy wait)
    }
    S--;
}

signal(S) {
    S++;
}

```

But busy waiting is inefficient, so real OSes implement it like this:

- If `S <= 0`:
    - The calling process/thread is put into the **blocked state** and added to a waiting queue.
- In `signal(S)`:
    - A process/thread from the waiting queue is removed and **woken up**.

**Types of semaphores**

- **Counting semaphore**
    - `S` is a non-negative integer.
    - Can represent multiple identical resources (e.g., 10 buffer slots).
- **Binary semaphore**
    - `S` can only be 0 or 1.
    - Functionally very similar to a **mutex**.

---

### Monitor

Semaphores are powerful but **easy to misuse and error-prone**:

- You must manually place `wait()` / `signal()` calls around every critical section.
- If you forget one or call them in the wrong order, you can easily introduce bugs.

To address this, the concept of a **monitor** was introduced.

> A monitor is an abstraction that bundles shared data together with the operations (methods) that access it,
> 
> 
> and **automatically provides mutual exclusion and condition synchronization** within that abstraction.
> 

**Key properties of a monitor**

- Shared data can be accessed **only through the monitor’s methods**.
- At most **one process/thread** can be executing inside the monitor at any time.
    
    → Mutual exclusion is **enforced automatically**.
    
- For waiting on and signaling specific conditions (e.g., buffer empty/full),
    
    the monitor uses **condition variables**.
    

---

### Condition Variables and Operations

A condition variable typically provides two operations:

- `wait(cond)`
    - Used when a thread needs to **wait for a condition** to become true.
    - The calling thread:
        - **Releases the monitor lock** and suspends itself, and
        - Goes to sleep in the `cond`’s waiting queue.
    - Later, when `signal(cond)` is called, it is woken up and can re-enter the monitor.
- `signal(cond)`
    - Wakes up **one thread** that is waiting on the corresponding condition variable.

Example: Producer–Consumer with a monitor

Inside the monitor:

- Shared buffer + methods like `insert()` and `remove()`
- Condition variables such as `notFull` and `notEmpty`

Behavior:

- Producer:
    - If the buffer is full → calls `wait(notFull)` and sleeps.
    - When there is space:
        - Calls `insert()` to add an item.
        - Then calls `signal(notEmpty)` to wake a waiting consumer (if any).
- Consumer:
    - If the buffer is empty → calls `wait(notEmpty)` and sleeps.
    - When an item is available:
        - Calls `remove()` to take an item.
        - Then calls `signal(notFull)` to wake a waiting producer (if any).

> Java’s synchronized methods/blocks + wait() / notify() pattern
> 
> 
> are a language-level implementation of the **monitor** concept.
>
